{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIKE MINNEBACH - 500903092 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #to write regex\n",
    "import pandas as pd #for the dataframe\n",
    "import datetime #for date formatting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a MT103 SWIFT message \n",
    "(https://www2.swift.com/knowledgecentre/products/Standards%20MT) into the \n",
    "following data structure. Write a code in your chosen language to convert the message to \n",
    "the following data structure. The notEmpty fields are mandatory. (25 points)\n",
    "Converting each of the mandatory fields correctly carries 1 point and converting each of \n",
    "the non-mandatory fields contains 0.5 points (15+8.5+1.5). 1.5 points are given for coding \n",
    "style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"MT103.txt\", 'r') #read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate lookup variables\n",
    "transaction_re = re.compile(r'transaction_|instrument_|originator_|beneficiary_|ingoing_|outgoing_*') #regex to identify the items which are needed in the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transaction_date</td>\n",
       "      <td>xDateTimeTz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transaction_id</td>\n",
       "      <td>notEmpty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transaction_message</td>\n",
       "      <td>notEmpty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transaction_currency</td>\n",
       "      <td>No value entered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transaction_amount</td>\n",
       "      <td>notEmpty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   item             value\n",
       "0      transaction_date       xDateTimeTz\n",
       "1        transaction_id          notEmpty\n",
       "2   transaction_message          notEmpty\n",
       "3  transaction_currency  No value entered\n",
       "4    transaction_amount          notEmpty"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loop through file\n",
    "\n",
    "columns = [] #initiate columns list\n",
    "values = [] #initiate values list\n",
    "\n",
    "for line in file.read().split('\\n'): #start for loop for each row in the .txt file\n",
    "    if transaction_re.search(line): #if row starts with the value(s) mentioned in the regex, keep row\n",
    "        item = line.split() #split row to extract the item (transaction id etc.) and corresponding value. This returns a list ['item', 'value']\n",
    "        columns.append(item[0].replace(\":\",\"\")) #append item to columns, remove \":\" for tidiness\n",
    "        try: #start try except for the values, as some values are empty, which stops Python\n",
    "            values.append(item[1]) #append value to values\n",
    "        except IndexError: #indexerrors occur when an index is appointed which is not available. Thus in case no value is entered. \n",
    "            values.append(\"No value entered\") #if there is no value, append \"No value entered\" \n",
    "\n",
    "df = pd.DataFrame([columns, values], index=['item', 'value']).T.explode('value') #code from https://stackoverflow.com/questions/66615474/create-a-pandas-dataframe-from-two-lists-column-1-is-first-list-column-2-is-se\n",
    "#explode() method is used to transform each element of a list to a separate record.\n",
    "\n",
    "df.head() #print first five rows of the df to see what we are dealing with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>transaction_message</th>\n",
       "      <th>transaction_currency</th>\n",
       "      <th>transaction_amount</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>transaction_direction</th>\n",
       "      <th>transaction_status</th>\n",
       "      <th>instrument_type</th>\n",
       "      <th>originator_full_name</th>\n",
       "      <th>...</th>\n",
       "      <th>beneficiary_first_name</th>\n",
       "      <th>beneficiary_middle_names_patronymic</th>\n",
       "      <th>beneficiary_last_name</th>\n",
       "      <th>beneficiary_address</th>\n",
       "      <th>beneficiary_country</th>\n",
       "      <th>beneficiary_account_number</th>\n",
       "      <th>beneficiary_branch_id</th>\n",
       "      <th>beneficiary_bic</th>\n",
       "      <th>beneficiary_fi_name</th>\n",
       "      <th>beneficiary_fi_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [transaction_date, transaction_id, transaction_message, transaction_currency, transaction_amount, transaction_type, transaction_direction, transaction_status, instrument_type, originator_full_name, originator_first_name, originator_middle_names_patronymic, originator_last_name, originator_address, originator_country, originator_account_number, originator_branch_id, originator_bic, originator_fi_name, originator_fi_country, outgoing_intermediary_fi_bic, beneficiary_full_name, beneficiary_first_name, beneficiary_middle_names_patronymic, beneficiary_last_name, beneficiary_address, beneficiary_country, beneficiary_account_number, beneficiary_branch_id, beneficiary_bic, beneficiary_fi_name, beneficiary_fi_country]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 32 columns]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transforming the df, so the items are columns and the values are the rows (easier if you want to loop through multiple files instantaneously)\n",
    "\n",
    "#transpose\n",
    "df = df.transpose() #columns, rows as explained above\n",
    "\n",
    "#column names are the first row\n",
    "df.columns = df.iloc[0] \n",
    "\n",
    "#remove the first row, as these are the column names\n",
    "df = df[1:1]\n",
    "\n",
    "#transform date to date format\n",
    "#df[\"transaction_date\"][0] = datetime.datetime.strptime(df[\"transaction_date\"][0],\"%d/%m/%Y\").date() #code from https://stackoverflow.com/questions/2803852/python-date-string-to-date-object\n",
    "\n",
    "#drop // columns, which was erroneously extracted\n",
    "df.drop(\"//\",axis=1,inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the right datatypes\n",
    "\n",
    "df['transaction_date'] = pd.to_datetime(df['transaction_date'])\n",
    "\n",
    "df = df.astype({'transaction_id':'string',\n",
    "                'transaction_message':'string',\n",
    "                'transaction_currency':'string',\n",
    "                'transaction_amount':'float',\n",
    "                'transaction_type':'string',\n",
    "                'transaction_direction':'string',\n",
    "                'transaction_status':'string',\n",
    "                'instrument_type':'string',\n",
    "                'originator_full_name':'string',\n",
    "                'originator_first_name':'string',\n",
    "                'originator_middle_names_patronymic':'string',\n",
    "                'originator_last_name':'string',\n",
    "                'originator_address':'string',\n",
    "                'originator_country':'string',\n",
    "                'originator_account_number':'string',\n",
    "                'originator_branch_id':'string',\n",
    "                'originator_bic':'string',\n",
    "                'originator_fi_name':'string',\n",
    "                'originator_fi_country':'string',\n",
    "                'outgoing_intermediary_fi_bic':'string',\n",
    "                'beneficiary_full_name':'string',\n",
    "                'beneficiary_first_name':'string',\n",
    "                'beneficiary_middle_names_patronymic':'string',\n",
    "                'beneficiary_branch_id':'string',\n",
    "                'beneficiary_bic':'string',\n",
    "                'beneficiary_fi_name':'string',\n",
    "                'beneficiary_fi_country':'string'})\n",
    "\n",
    "#df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the file \n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the dataframe with  SWIFT MT103 messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSAGE1 = (\n",
    "    \"{1:F01ASDFJK20AXXX0987654321}\"\n",
    "    \"{2:I103ASDFJK22XXXXN}\"\n",
    "    \"{4: :20:20180101-ABCDEF :23B:GHIJ :32A:180117CAD5432,1 :33B:EUR9999,0 :50K:/123456-75901 SOMEWHERE New York 999999 GR :53B:/20100213012345 :57C://SC200123 :59:/201001020 First Name Last Name a12345bc6d789ef01a23 Nowhere NL :70:test reference test reason payment group: 1234567-ABCDEF :71A:SHA :77B:Test this -}\"  # NOQA: E501\n",
    ")\n",
    "MESSAGE2 = (\n",
    "    \"{1:F01QWERTY22AXXX1234567890}\"\n",
    "    \"{2:I103QWERTY33XXXXA7}\"\n",
    "    \"{3:{108:MT103}}\"\n",
    "    \"{4:\\n:20:1234567-8901\\n:23B:ABCD\\n:32A:000625EUR1000,00\\n:33B:EUR1000,00\\n:50K:COMPANY NAME\\nNAPLES\\n:52A:ABCDEFGH123\\n:53A:ABCDEF12\\n:54A:ABCDEF1G\\n:57A:ABCDEFGHIJK\\n:59:/20061120050500001A01234\\nBENEFICIARY NAME\\n:70:/REMITTANCE INFO\\n:71A:SHA\\n-}\"  # NOQA: E501\n",
    ")\n",
    "MESSAGE3 = (\n",
    "    \"{1:F01QWERTY22AXXX1234567890}\"\n",
    "    \"{2:I103QWERTY33XXXXA7}\"\n",
    "    \"{3:{113:SEPA}{111:001}{121:d2d62e74-4f7d-45dc-a230-85fa259e1694}}\"\n",
    "    \"{4: :20:123456-ABCDEF001 :23B:GHIJ :32A:123456GBP10000,00 :33B:GBP10000,00 :50K:/This is arbitrary text :52D:/123456-78900 More arbitrary text :53B:/12345678901234 :57C://AB123456 :59:/12345678 Even more arbitrary text :70:abc - 12.34 more txt 20190115-ABCDEF :71A:SHA :72:/INS/ABCDEF01 -}\"  # NOQA: E501\n",
    ")\n",
    "MESSAGE4 = (\n",
    "    \"{1:F01AAAAGRA0AXXX0057000289}\"\n",
    "    \"{2:O1030919010321BBBBGRA0AXXX00570001710103210920N}\"\n",
    "    \"{3:{108:MT103 003 OF 045}{121:c8b66b47-2bd9-48fe-be90-93c2096f27d2}}\"\n",
    "    \"{4:\\n:20:5387354\\n:23B:CRED\\n:23E:PHOB/20.527.19.60\\n:32A:000526USD1101,50\\n:33B:USD1121,50\\n:50K:FRANZ HOLZAPFEL GMBH\\nVIENNA\\n:52A:BKAUATWW\\n:59:723491524\\nC. KLEIN\\nBLOEMENGRACHT 15\\nAMSTERDAM\\n:71A:SHA\\n:71F:USD10,\\n:71F:USD10,\\n:72:/INS/CHASUS33\\n-}\"\n",
    "    \"{5:{MAC:75D138E4}{CHK:DE1B0D71FA96}}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set directory with files to loop through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':F01AAAAGRA0AXXX0057000289',\n",
       " ':O1030919010321BBBBGRA0AXXX00570001710103210920N',\n",
       " ':MT103',\n",
       " ':c8b66b47',\n",
       " ':20:',\n",
       " ':23B:',\n",
       " ':23E:',\n",
       " ':32A:',\n",
       " ':33B:',\n",
       " ':50K:',\n",
       " ':52A:',\n",
       " ':59:',\n",
       " ':71A:',\n",
       " ':71F:',\n",
       " ':71F:',\n",
       " ':72:',\n",
       " ':75D138E4',\n",
       " ':DE1B0D71FA96']"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initiate lookup variables\n",
    "swift_re = re.compile(r':[A-Za-z0-9?]+:*') #regex to identify the items which are needed in the dataframe\n",
    "\n",
    "\n",
    "\n",
    "swift_re.findall(MESSAGE4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1:F01AAAAGRA0AXXX0057000289}{2:O1030919010321BBBBGRA0AXXX00570001710103210920N}{3:{108:MT103 003 OF 045}{121:c8b66b47-2bd9-48fe-be90-93c2096f27d2}}{4:\n",
      ":20:5387354\n",
      ":23B:CRED\n",
      ":23E:PHOB/20.527.19.60\n",
      ":32A:000526USD1101,50\n",
      ":33B:USD1121,50\n",
      ":50K:FRANZ HOLZAPFEL GMBH\n",
      "VIENNA\n",
      ":52A:BKAUATWW\n",
      ":59:723491524\n",
      "C. KLEIN\n",
      "BLOEMENGRACHT 15\n",
      "AMSTERDAM\n",
      ":71A:SHA\n",
      ":71F:USD10,\n",
      ":71F:USD10,\n",
      ":72:/INS/CHASUS33\n",
      "-}{5:{MAC:75D138E4}{CHK:DE1B0D71FA96}}\n"
     ]
    }
   ],
   "source": [
    "#loop through files and look for re compiled information, append this info to df\n",
    "for line in MESSAGE4.split('\\n'): #start for loop for each row in the .txt file\n",
    "    print(line)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this structure to either write python functions or sql code to identify the following risk \n",
    "patterns (75 points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a. Round Amount payments - 15 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mg:\\Mijn Drive\\School\\Master in Digital Driven Business - AUAS Amsterdam\\Q3\\1. Fintech Systems dev\\Assignment\\Mike_Minnebach_500903092_FinTech_SysDev.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Mijn%20Drive/School/Master%20in%20Digital%20Driven%20Business%20-%20AUAS%20Amsterdam/Q3/1.%20Fintech%20Systems%20dev/Assignment/Mike_Minnebach_500903092_FinTech_SysDev.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m amount \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(df[\u001b[39m\"\u001b[39;49m\u001b[39mtransaction_amount\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Mijn%20Drive/School/Master%20in%20Digital%20Driven%20Business%20-%20AUAS%20Amsterdam/Q3/1.%20Fintech%20Systems%20dev/Assignment/Mike_Minnebach_500903092_FinTech_SysDev.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m amount \u001b[39m%\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Mijn%20Drive/School/Master%20in%20Digital%20Driven%20Business%20-%20AUAS%20Amsterdam/Q3/1.%20Fintech%20Systems%20dev/Assignment/Mike_Minnebach_500903092_FinTech_SysDev.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     df[\u001b[39m\"\u001b[39m\u001b[39misRound\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mikem\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:955\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    952\u001b[0m     key \u001b[39m=\u001b[39m unpack_1tuple(key)\n\u001b[0;32m    954\u001b[0m \u001b[39mif\u001b[39;00m is_integer(key) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_should_fallback_to_positional:\n\u001b[1;32m--> 955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m    958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_value(key)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "amount = int(df[\"transaction_amount\"][0])\n",
    "\n",
    "if amount % 1000 == 0:\n",
    "    df[\"isRound\"] = True\n",
    "else:\n",
    "    df[\"isRound\"] = False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b. Payments from high risk countries -15 points (https://www.fatf\u0002gafi.org/en/countries/black-and-grey-lists.html) to tax havens \n",
    "(https://fsi.taxjustice.no/fsi/2022/world/score/top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "originator_country = df[\"originator_country\"][0]\n",
    "beneficiary_country = df[\"beneficiary_country\"][0]\n",
    "\n",
    "high_risk_countries = [\"NC\", \"IR\", \"MY\", \"AL\", \"BA\", \"BU\", \"CA\", \"CO\", \"GI\", \"HA\", \"JA\", \"JO\", \"MA\", \"MO\", \"NI\", \"PA\", \"PH\", \"SE\", \"SA\", \"SS\", \"SY\", \"TA\", \"TU\", \"UG\", \"UA\", \"YE\"]\n",
    "tax_havens = [\"VI\", \"AN\", \"BO\", \"UA\", \"AL\", \"PU\", \"CU\"] \n",
    "\n",
    "if originator_country in high_risk_countries and beneficiary_country in tax_havens:\n",
    "    df[\"suspCountries\"] = True\n",
    "else:\n",
    "    df[\"suspCountries\"] = False\n",
    "\n",
    "print(df[\"suspCountries\"][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Smurfing -10 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transaction is within the date threshold: True\n",
      "The transaction is within the amount threshold: False\n",
      "The transaction is within the count threshold: False\n"
     ]
    }
   ],
   "source": [
    "#som per originator_account_number\n",
    "#if over past X days at least N cash deposits were made with an amount between the fix threshold (10k) and [100 - CD(n) * 2%] of that amount (38:29)\n",
    "import datetime\n",
    "\n",
    "date_thres = 7 #X\n",
    "cd_thres = 2 #N\n",
    "fixed_threshold = 10000\n",
    "var_threshold = fixed_threshold - cd_thres * 0.02 #create dynamic threshold within 2% of the original threshold times the number of transactions\n",
    "reference_date = datetime.date(2023,3,20)\n",
    "transaction_date = df[\"transaction_date\"][0]\n",
    "\n",
    "#we will work based on three IF's: data threshold (number of days between transactions date and reference date), amount threshold (if between two thresholds 'True') and cash deposits (check the number of transactions versus set threshold of transactions) \n",
    "#first we will check the IF's on transaction level, which are the days between transactions and amount.\n",
    "\n",
    "#IF check if transaction date is within 7 days of reference date\n",
    "datetime.timedelta(7) #initiate timedelta with 7 \n",
    "if -date_thres <= (transaction_date-reference_date).days: #calculate the days between the ref. date and trans. date, if smaller or equal to the data threshold continue\n",
    "    df[\"inDataThres\"] = True\n",
    "else:\n",
    "    df[\"inDataThres\"] = False\n",
    "\n",
    "print(\"The transaction is within the date threshold: \" + str(df[\"inDataThres\"][0]))\n",
    "\n",
    "#IF check threshold\n",
    "if fixed_threshold >= amount and var_threshold <= amount:\n",
    "    df[\"inAmtThres\"] = True\n",
    "else:\n",
    "   df[\"inAmtThres\"] = False\n",
    "\n",
    "print(\"The transaction is within the amount threshold: \" + str(df[\"inAmtThres\"][0]))\n",
    "\n",
    "#now we will check whether the total count of transactions is within the threshold. For this we group the DF.\n",
    "#IF check the number of transactions (returns one as we only have 1 example in the database, consequently assumes multiple MT103 transactions in the database)\n",
    "count = df.groupby(['originator_account_number'])['transaction_amount'].count()[0] #counts the number of transactions, grouped by originator account number If it exceeds the set threshold, 'True'.\n",
    "\n",
    "if count > cd_thres:\n",
    "    df[\"over_cd_thres\"] = True\n",
    "else:\n",
    "    df[\"over_cd_thres\"] = False\n",
    "    \n",
    "print(\"The transaction is within the count threshold: \" + str(df[\"over_cd_thres\"][0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nesting -10 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of accounts transferring money to the beneficiary is: 1\n",
      "The number of unique accounts transferring money to the beneficiary is: 1\n"
     ]
    }
   ],
   "source": [
    "#for nesting we will assess the number of origin accounts that transfer money to the beneficiary. \n",
    "\n",
    "count_nesting = df.groupby(['beneficiary_account_number'])['originator_account_number'].count()[0] #counts the number of transactions that transfer money to the beneficiary, grouped by beneficiary account number.\n",
    "print(\"The number of accounts transferring money to the beneficiary is: \" + str(count_nesting))\n",
    "\n",
    "count_nesting_un = df.groupby(['beneficiary_account_number'])['originator_account_number'].nunique()[0] #counts the number of unique account numbers that transfer money to the beneficiary, grouped by  beneficiary account number.\n",
    "print(\"The number of unique accounts transferring money to the beneficiary is: \" + str(count_nesting_un))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Non-adherence to FATF Recommendation 16 -10 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transaction does comply with FATF\n",
      "------------------------------------------------------\n",
      "The following columns miss values: \n",
      "transaction_message\n",
      "transaction_type\n",
      "originator_first_name\n",
      "originator_middle_names_patronymic\n",
      "originator_last_name\n",
      "originator_bic\n",
      "originator_fi_name\n",
      "originator_fi_country\n",
      "beneficiary_full_name\n",
      "beneficiary_first_name\n",
      "beneficiary_middle_names_patronymic\n",
      "beneficiary_last_name\n",
      "beneficiary_address\n",
      "beneficiary_account_number\n",
      "beneficiary_bic\n",
      "beneficiary_fi_name\n",
      "beneficiary_fi_country\n"
     ]
    }
   ],
   "source": [
    "#FATF basically states that all info should be there in a MT103 file. In case the value notEmpty (which is a mandatory field) is present, NonComplFATF is 'True'\n",
    "\n",
    "emptycols = []\n",
    "\n",
    "for item in df:\n",
    "    if df[item][0] == \"notEmpty\": #check for notEmpty\n",
    "        df[\"NonComplFATF\"] = True\n",
    "        emptycols.append(item)\n",
    "    elif df[item][0] == \"\": #check for just empty items\n",
    "        df[\"NonComplFATF\"] = True\n",
    "        emptycols.append(item)\n",
    "    else:\n",
    "        df[\"NonComplFATF\"] = False \n",
    "\n",
    "if (df[\"NonComplFATF\"][0]) == False:\n",
    "    print(\"The transaction does comply with FATF\")\n",
    "else:\n",
    "    print(\"The transaction does not comply with FATF\")\n",
    "\n",
    "print(\"------------------------------------------------------\")\n",
    "\n",
    "\n",
    "print(\"The following columns miss values: \")\n",
    "for emptycol in emptycols: print(emptycol)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> f. (https://www.fatf\u0002gafi.org/content/dam/recommandations/pdf/FATF%20Recommendations%20201\n",
    "2.pdf.coredownload.inline.pdf) - 5 points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> g. Shell company characteristics using address and name data. - 5 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transaction does not originate from a Shell company\n"
     ]
    }
   ],
   "source": [
    "#to identify a shell company we assess the address and name data. In case it is missing (or empty or notEmpty), we will identify the transaction as isShellComp = True. We will assess the fields originator_full_name and originator_address, as these are mandatory (notEmpty) fields.\n",
    " \n",
    "if (df[\"originator_address\"][0]) == \"notEmpty\" or (df[\"originator_address\"][0]) == \"\" or (df[\"originator_full_name\"][0]) == \"notEmpty\" or (df[\"originator_full_name\"][0]) == \"\":\n",
    "    df[\"isShellComp\"] = True\n",
    "else:\n",
    "    df[\"isShellComp\"] = False\n",
    "\n",
    "if df[\"isShellComp\"][0] == True:\n",
    "    print(\"The transaction could originate from a Shell company\")\n",
    "else:\n",
    "    print(\"The transaction does not originate from a Shell company\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Trade based money laundering - 5 points\n",
    "(https://www.fatf-gafi.org/content/fatf\u0002gafi/en/publications/Methodsandtrends/Trade-based-money-laundering\u0002indicators.html, https://stats.wto.org/dashboard/tradeconnectivity_en.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('MT103_analysis.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
